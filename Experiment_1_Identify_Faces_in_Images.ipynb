{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ...\n",
      "520\n"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "print(\"running ...\")\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "cascadePath = \"Classifiers/face.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "path = 'dataset2/originalPics/2003/04/03/big/'\n",
    "def get_images_and_labels(path):\n",
    "     lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "     upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "     image_paths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "     # images will contains face images\n",
    "     images = []\n",
    "     # labels will contains the label that is assigned to the image\n",
    "     labels = []\n",
    "     for image_path in image_paths:\n",
    "         # Read the image and convert to grayscale\n",
    "         image_pil = Image.open(image_path)\n",
    "         # Convert the image format into numpy array\n",
    "         image = np.array(image_pil, 'uint8')\n",
    "         \n",
    "         # Get the label of the image\n",
    "         nbr = random.randint(1,1000)#os.path.split(image_path)[1].split(\".\")[0].replace(\"face-\", \"\")\n",
    "         #nbr=int(''.join(str(ord(c)) for c in nbr))\n",
    "         print nbr\n",
    "         # Detect the face in the image\n",
    "         faces = faceCascade.detectMultiScale(image,            \n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "         # If face is detected, append the face to images and the label to labels\n",
    "         for (x, y, w, h) in faces:\n",
    "             maskedImage = image[:]\n",
    "             images.append(image[y: y + h, x: x + w])\n",
    "             labels.append(nbr)\n",
    "             fig = plt.figure(figsize=(10, 30))\n",
    "             plt.subplot(1, 5, 1)\n",
    "             plt.title(\"original picture\")\n",
    "             plt.imshow(image,cmap='gray')\n",
    "                \n",
    "             face_region = image[y: y + h, x: x + w]\n",
    "             converted = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "             plt.subplot(1, 5, 5)\n",
    "             #resImage = cv2.inpaint(image,skinMask,8,cv2.INPAINT_NS)\n",
    "             maskedImage[y: y + h, x: x + w] = get_drawRectangleAroundImage(face_region)\n",
    "             #resImage = cv2.add(image,skinMask)\n",
    "             plt.imshow(maskedImage)\n",
    "             plt.show()\n",
    "                \n",
    "                \n",
    "             cv2.waitKey(10)\n",
    "     # return the images list and labels list\n",
    "     return images, labels\n",
    "\n",
    "def get_drawRectangleAroundImage(img):\n",
    "    height, width, channels = img.shape\n",
    "    img = cv2.rectangle(img,(0,0),(height,width),(0,255,0),10)\n",
    "    return img    \n",
    "    \n",
    "\n",
    "images, labels = get_images_and_labels(path)\n",
    "#cv2.imshow('test',images[0])\n",
    "cv2.waitKey(1)\n",
    "\n",
    "#recognizer.train(images, np.array(labels))\n",
    "#recognizer.write('trainer/trainer.yml')\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
